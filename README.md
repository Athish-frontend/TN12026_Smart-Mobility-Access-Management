# Enhancing Brain-Computer Interface Efficiency for Real-Time Wheelchair Control

## Overview
The **Brain-Controlled Smart Wheelchair** is a hands-free mobility system designed for individuals with severe motor disabilities.  
It uses **non-invasive EEG signals** to capture brain activity, which is processed in real time using **machine learning algorithms** and then translated into wheelchair movement commands.  

The prototype is built using:
- Arduino Uno  
- HC-05 Bluetooth module  
- L298N motor driver  
- EEG headset (or laptop preprocessing for cost efficiency)  

In future versions, it will also include **obstacle detection sensors** and **LM2596-based power management**, ensuring both safety and reliability.  
Unlike traditional wheelchairs that depend on manual controls or voice commands, this prototype allows users to move using only their thoughts.  
With its **low-cost, offline-capable, and scalable design**, the system is suitable for deployment in **hospitals, rehabilitation centers, and personal use**, empowering motor-disabled individuals with **independence and dignity**.

---

## Features
- **EEG-based control** – Converts brain signals into forward, backward, left, and right movements.  
- **Real-time preprocessing & ML** – Ensures responsive and accurate signal interpretation.  
- **Safety-first design** – Threshold logic, duplicate command filtering, and obstacle avoidance sensors.  

---

## Functionalities
- **EEG Input:** NeuroSense MindWave (prototype uses laptop preprocessing)  
- **Microcontroller:** Arduino Uno  
- **Communication:** HC-05 Bluetooth Module  

---

## Problem Statement
Millions of people suffering from **ALS, spinal cord injuries, strokes, and neuromuscular diseases** are deprived of voluntary muscle control, making conventional wheelchairs unusable.  

**Core problem:** Lack of an **intuitive, non-invasive, and independent mobility solution** for individuals with severe motor impairments.  

---

## Our Solution
The prototype addresses this gap by providing:
- Hands-free navigation through **EEG brain signals**.  
- **Real-time processing and machine learning** for reliability.  
- **Scalable, low-cost hardware** suitable for hospitals, rehab centers, and personal use.  

This innovation restores **independence, dignity, and social inclusion** for individuals with limited mobility.  

---

## Impact & Scalability
- **Low-cost and accessible hardware** (Arduino, L298N, EEG headset).  
- **Easily replicable infrastructure** for deployment in hospitals, care centers, or public events.  
- **Offline-capable system** ensures usability in both rural and urban areas.  

---

## Future Scope
- **AI integration** for intent prediction (eye-tracking, facial expressions, voice commands).  
- **IoT & Cloud connectivity** for caregiver monitoring and remote assistance.  
- **Health monitoring** (ECG, BP, SpO₂) with emergency alerts.  

---

##  Repository
[GitHub Repository Link](https://github.com/Athish-frontend/TN12026_Smart-Mobility-Access-Management.git)

---
